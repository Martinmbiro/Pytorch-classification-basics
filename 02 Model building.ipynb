{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNkY46mFNawWEQmnQtjHxQX",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Martinmbiro/Pytorch-classification-basics/blob/main/02%20Model%20building.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Data loading & model building**\n",
        "> For this notebook, I'll functionizing the code to load the [Iris dataset](https://en.wikipedia.org/wiki/Iris_flower_data_set) as well as build a neural network for the multi-class classification task"
      ],
      "metadata": {
        "id": "-14ZyW6246dL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Loading data\n",
        "> Here, I functionize the code for loading the Iris dataset. The function will execute the following steps:\n",
        "+ Load the Iris dataset\n",
        "+ Preprocess the data (scale and take care of missing values)\n",
        "+ Return `X`, `y` and `target labels`"
      ],
      "metadata": {
        "id": "-TJJwYXU7VHR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# import\n",
        "import numpy as np\n",
        "# for type hinting\n",
        "from typing import Tuple"
      ],
      "metadata": {
        "id": "o5RUWUvo6v1T"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# define function to load dataset\n",
        "def load_dataset() -> Tuple[np.ndarray, np.ndarray, np.ndarray]:\n",
        "  # make necessary imports\n",
        "  from sklearn import datasets\n",
        "  # for data preprocessing\n",
        "  from sklearn.preprocessing import MinMaxScaler\n",
        "  from sklearn.impute import SimpleImputer\n",
        "  from sklearn.pipeline import make_pipeline\n",
        "\n",
        "  # load the dataset\n",
        "  iris = datasets.load_iris()\n",
        "\n",
        "  # make pipeline for preprocessing the features\n",
        "  preprocessor = make_pipeline(\n",
        "      SimpleImputer(strategy='median'), # handle missing values (if any)\n",
        "      MinMaxScaler() # scale data from 0 -> 1\n",
        "  )\n",
        "\n",
        "  # preprocess the features\n",
        "  X = preprocessor.fit_transform(iris.data)\n",
        "  # get labels\n",
        "  y = iris.target\n",
        "\n",
        "  # return X, y, target_names\n",
        "  return X, y, iris.target_names"
      ],
      "metadata": {
        "id": "9_Wrizfa2_s-"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# test out the function\n",
        "X, y, target_names = load_dataset()"
      ],
      "metadata": {
        "id": "nVaI4Ml35OMn"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# first 5 rows in X\n",
        "X[:5]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X1SI6zcl6gsW",
        "outputId": "102f0df9-e1c4-434e-9ec3-9072c96581b6"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.22222222, 0.625     , 0.06779661, 0.04166667],\n",
              "       [0.16666667, 0.41666667, 0.06779661, 0.04166667],\n",
              "       [0.11111111, 0.5       , 0.05084746, 0.04166667],\n",
              "       [0.08333333, 0.45833333, 0.08474576, 0.04166667],\n",
              "       [0.19444444, 0.66666667, 0.06779661, 0.04166667]])"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# last 10 values in y\n",
        "y[140:]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VcRvK7NY6kCx",
        "outputId": "df78bf8b-5404-43d9-d233-ea3e6a70ca68"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([2, 2, 2, 2, 2, 2, 2, 2, 2, 2])"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# get random labels\n",
        "ls = [y[i] for i in np.random.randint(0, 149, size=(5,))]\n",
        "\n",
        "# print target names of random labels in y\n",
        "[target_names[x] for x in ls]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4fCi2COX85vk",
        "outputId": "d8573ef9-81da-4bc5-894c-d4d5ac983507"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['versicolor', 'setosa', 'versicolor', 'setosa', 'versicolor']"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# how many unique elements do we have as target?\n",
        "np.unique(y).size"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5VuQX7ld2p2-",
        "outputId": "ef6ddacb-175c-4732-8a94-33faf7be005c"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "> 🎆 **Bingo!**\n",
        "\n",
        "> The function to load our data seems to be working fine. Now let's build the model"
      ],
      "metadata": {
        "id": "6c12FK8F-6RL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Building the model\n",
        "> ✋ **Info**  \n",
        "\n",
        "> For the neural network,\n",
        "+ We'll stack [`nn.Linear`](https://pytorch.org/docs/stable/generated/torch.nn.Linear.html#linear) with [`nn.Sequential`](https://pytorch.org/docs/stable/generated/torch.nn.Sequential.html#torch.nn.Sequential) such that we'll end up with two _hidden layers_ between the _input_ and _output layers._\n",
        "+ [`nn.Relu`](https://pytorch.org/docs/stable/generated/torch.nn.ReLU.html#torch.nn.ReLU) activation function will be used to introduce non-linearity\n",
        "+ Since this is a multi-class classification task (we have `3` distinct classes) , we'll have the output layer with `3` neurons"
      ],
      "metadata": {
        "id": "zTRXom3h6wgu"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "ID5KyYQg2I7r",
        "outputId": "b617bb27-fa36-40b8-88bf-d374fe6012c5"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'2.5.1+cu121'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "# import torch\n",
        "import torch, torch.nn as nn\n",
        "torch.__version__"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# stacking the layers\n",
        "model = nn.Sequential(\n",
        "    nn.Linear(in_features=X.shape[1], out_features=8), # input -> hidden layer 1\n",
        "    nn.ReLU(),\n",
        "    nn.Linear(8, 8), # hidden layer 1 -> hidden layer 2\n",
        "    nn.ReLU(),\n",
        "    nn.Linear(8, 3), # hidden layer 2 -> outplut layer\n",
        ")"
      ],
      "metadata": {
        "id": "gfZZLtTB4x8n"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Visualize the structure of the neural network\n",
        "> To do this, we'll use [`torchinfo`](https://github.com/TylerYep/torchinfo)"
      ],
      "metadata": {
        "id": "4QhoVeg77NEz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# install the library\n",
        "!pip install torchinfo\n",
        "# import summary\n",
        "from torchinfo import summary"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m2i5YPgj69T7",
        "outputId": "c04fba20-743a-45f5-84b0-9abfc0bb1f93"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting torchinfo\n",
            "  Downloading torchinfo-1.8.0-py3-none-any.whl.metadata (21 kB)\n",
            "Downloading torchinfo-1.8.0-py3-none-any.whl (23 kB)\n",
            "Installing collected packages: torchinfo\n",
            "Successfully installed torchinfo-1.8.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "summary(model, input_size=(4,))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y-qZ79KA7ron",
        "outputId": "67d99ed3-7019-4906-cf31-fdcc1c3bbe4e"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "==========================================================================================\n",
              "Layer (type:depth-idx)                   Output Shape              Param #\n",
              "==========================================================================================\n",
              "Sequential                               [3]                       --\n",
              "├─Linear: 1-1                            [8]                       40\n",
              "├─ReLU: 1-2                              [8]                       --\n",
              "├─Linear: 1-3                            [8]                       72\n",
              "├─ReLU: 1-4                              [8]                       --\n",
              "├─Linear: 1-5                            [3]                       27\n",
              "==========================================================================================\n",
              "Total params: 139\n",
              "Trainable params: 139\n",
              "Non-trainable params: 0\n",
              "Total mult-adds (M): 0.00\n",
              "==========================================================================================\n",
              "Input size (MB): 0.00\n",
              "Forward/backward pass size (MB): 0.00\n",
              "Params size (MB): 0.00\n",
              "Estimated Total Size (MB): 0.00\n",
              "=========================================================================================="
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "> ▶️ **Up Next**\n",
        "\n",
        "> Model training and evaluation"
      ],
      "metadata": {
        "id": "pGqDUavE_ma_"
      }
    }
  ]
}